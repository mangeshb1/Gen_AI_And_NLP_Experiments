{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "gpu"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9811fb6988c2468f91ca5c05f8195816": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46b7618b10484cba854df12fd7d6256d",
              "IPY_MODEL_177abcacf3fe44948226bc6769934c4f",
              "IPY_MODEL_e0e5124c8aca436082b29c945800bed1"
            ],
            "layout": "IPY_MODEL_e0923eed71a24c8f8f96e945834f4d67"
          }
        },
        "46b7618b10484cba854df12fd7d6256d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_197ee1c39b2649ddb4aa7d406cf35f31",
            "placeholder": "​",
            "style": "IPY_MODEL_67d634a8620642b2aff4ee9a9b73724f",
            "value": "Loading checkpoint shards:   0%"
          }
        },
        "177abcacf3fe44948226bc6769934c4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cc4f04588974c4fa2ce12d86b10fde5",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d52596605e354213bfc727dd503a349a",
            "value": 0
          }
        },
        "e0e5124c8aca436082b29c945800bed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84f10937c4b94cff9e32d525e5969acd",
            "placeholder": "​",
            "style": "IPY_MODEL_fb5a02e885f348ecb43e4d4568c56a4d",
            "value": " 0/3 [00:00&lt;?, ?it/s]"
          }
        },
        "e0923eed71a24c8f8f96e945834f4d67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "197ee1c39b2649ddb4aa7d406cf35f31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67d634a8620642b2aff4ee9a9b73724f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7cc4f04588974c4fa2ce12d86b10fde5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d52596605e354213bfc727dd503a349a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "84f10937c4b94cff9e32d525e5969acd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb5a02e885f348ecb43e4d4568c56a4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mangeshb1/Gen_AI_And_NLP_Experiments/blob/main/Gen_AI_And_NLP_Experiments/gpt_oss_safeguard_20b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers"
      ],
      "metadata": {
        "id": "CAKY9k5ONxG1",
        "outputId": "87c82caa-8e86-4ff6-e553-7ac851ff39df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Local Inference on GPU\n",
        "Model page: https://huggingface.co/openai/gpt-oss-safeguard-20b\n"
      ],
      "metadata": {
        "id": "F10str-_NxG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a pipeline as a high-level helper\n",
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=\"openai/gpt-oss-safeguard-20b\")\n",
        "# messages = [\n",
        "#     {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
        "# ]\n",
        "# pipe(messages)"
      ],
      "metadata": {
        "id": "HQXLO2kKNxG4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190,
          "referenced_widgets": [
            "9811fb6988c2468f91ca5c05f8195816",
            "46b7618b10484cba854df12fd7d6256d",
            "177abcacf3fe44948226bc6769934c4f",
            "e0e5124c8aca436082b29c945800bed1",
            "e0923eed71a24c8f8f96e945834f4d67",
            "197ee1c39b2649ddb4aa7d406cf35f31",
            "67d634a8620642b2aff4ee9a9b73724f",
            "7cc4f04588974c4fa2ce12d86b10fde5",
            "d52596605e354213bfc727dd503a349a",
            "84f10937c4b94cff9e32d525e5969acd",
            "fb5a02e885f348ecb43e4d4568c56a4d"
          ]
        },
        "outputId": "b76fbc11-e6f0-4930-ffce-72723d1653ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "MXFP4 quantization requires Triton and kernels installed: CUDA requires Triton >= 3.4.0, XPU requires Triton >= 3.5.0, we will default to dequantizing the model to bf16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9811fb6988c2468f91ca5c05f8195816"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example: policy + content\n",
        "policy = \"\"\"\n",
        "Policy: Do not allow hate speech. Hate speech is defined as content that attacks or demeans a person or group based on race, religion, gender, or sexual orientation.\n",
        "\"\"\"\n",
        "\n",
        "content = \"I think people of religion X are dangerous and should not be trusted.\"\n",
        "\n",
        "prompt = f\"{policy}\\n\\nContent: {content}\\n\\nDoes this content violate the policy? Explain your reasoning.\"\n",
        "\n",
        "# Run inference\n",
        "output = pipe(prompt, max_new_tokens=200, do_sample=False)\n",
        "print(output[0][\"generated_text\"])\n"
      ],
      "metadata": {
        "id": "Pz1YhssZPGXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"openai/gpt-oss-safeguard-20b\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"openai/gpt-oss-safeguard-20b\")\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "\tmessages,\n",
        "\tadd_generation_prompt=True,\n",
        "\ttokenize=True,\n",
        "\treturn_dict=True,\n",
        "\treturn_tensors=\"pt\",\n",
        ").to(model.device)\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens=40)\n",
        "print(tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:]))"
      ],
      "metadata": {
        "id": "wnaWkHRyNxG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pOQpGh4TOpwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remote Inference via Inference Providers\n",
        "Ensure you have a valid **HF_TOKEN** set in your environment. You can get your token from [your settings page](https://huggingface.co/settings/tokens). Note: running this may incur charges above the free tier.\n",
        "The following Python example shows how to run the model remotely on HF Inference Providers, automatically selecting an available inference provider for you.\n",
        "For more information on how to use the Inference Providers, please refer to our [documentation and guides](https://huggingface.co/docs/inference-providers/en/index)."
      ],
      "metadata": {
        "id": "P--wX2meNxG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Include your HF token here.\n",
        "import os\n",
        "os.environ['HF_TOKEN'] = ''"
      ],
      "metadata": {
        "id": "mcFajuVwNxG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url=\"https://router.huggingface.co/v1\",\n",
        "    api_key=os.environ[\"HF_TOKEN\"],\n",
        ")\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"openai/gpt-oss-safeguard-20b\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"What is the capital of France?\"\n",
        "        }\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "id": "58Gx3LDoNxG6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40a0f422-b723-45ef-d8fc-8aa79ab2e3ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content='The capital of France is **Paris**.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None, reasoning='The user asks: \"What is the capital of France?\" This is a straightforward question. We just answer: Paris. Also perhaps provide some context? But minimal.\\n\\nGiven this is a general knowledge question, answer accordingly.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "# Connect to Hugging Face router with OpenAI client\n",
        "client = OpenAI(\n",
        "    base_url=\"https://router.huggingface.co/v1\",\n",
        "    api_key=os.environ[\"HF_TOKEN\"],\n",
        ")\n",
        "\n",
        "# Define your policy and the content to evaluate\n",
        "policy = \"\"\"\n",
        "Policy: Do not allow hate speech. Hate speech is defined as content that attacks or demeans a person or group\n",
        "based on race, religion, gender, or sexual orientation.\n",
        "\"\"\"\n",
        "\n",
        "content = \"I think people of religion X are dangerous and should not be trusted.\"\n",
        "\n",
        "# Build the prompt in a way safeguard expects\n",
        "prompt = f\"{policy}\\n\\nContent: {content}\\n\\nDoes this content violate the policy? Explain your reasoning.\"\n",
        "\n",
        "# Call the model using chat.completions\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"openai/gpt-oss-safeguard-20b\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt\n",
        "        }\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Print both the classification and reasoning\n",
        "message = completion.choices[0].message\n",
        "print(\"Model Output:\\n\")\n",
        "print(\"Content:\", message.content)\n",
        "print(\"Reasoning:\", getattr(message, \"reasoning\", None))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8x12H3KQFwz",
        "outputId": "4ed6a974-7093-4123-feab-5cc8f2bfe1ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Output:\n",
            "\n",
            "Content: Yes.  \n",
            "The statement “people of religion X are dangerous and should not be trusted” is a blanket, negative characterization directed at a specific religious group. According to the policy, content that attacks or demeans a person or group based on religion is a form of hate speech and is not allowed. Therefore the content violates the policy.\n",
            "Reasoning: We need to check policy: hate speech: content that attacks or demeans a person or group based on race, religion, gender, or sexual orientation. The user says: \"I think people of religion X are dangerous and should not be trusted.\" That is a negative statement targeting a religious group; it's a generalization, potentially hate speech. According to policy, yes it violates. So answer: Yes, it does violate. Explanation: It's a hateful statement that demeaning a religious group, calling them dangerous and untrustworthy. It's a form of religious hate. So it is disallowed content. We should respond that it violates policy. Possibly we need to explain but not to provide a reason that is too long? The user asks: \"Does this content violate the policy? Explain your reasoning.\"\n",
            "\n",
            "Thus, answer: Yes, it violates. Provide reasoning: This is a statement that attacks or demeans a group based on religion, etc. The policy says disallowed. Provide explanation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import re\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url=\"https://router.huggingface.co/v1\",\n",
        "    api_key=os.environ[\"HF_TOKEN\"],\n",
        ")\n",
        "\n",
        "def classify_content(policies: dict, content: str):\n",
        "    results = {}\n",
        "\n",
        "    for name, policy_text in policies.items():\n",
        "        prompt = f\"\"\"\n",
        "INSTRUCTIONS:\n",
        "- Read the POLICY and CONTENT.\n",
        "- Return a JSON object with keys:\n",
        "  - violation (bool)\n",
        "  - category (string: one of [\"{name}\", \"not_applicable\"])\n",
        "  - rationale (string, <=2 sentences)\n",
        "  - confidence (float between 0 and 1)\n",
        "- IMPORTANT: Wrap the JSON ONLY inside triple backticks (```json ... ```).\n",
        "- Do not include any text outside the JSON.\n",
        "\n",
        "POLICY ({name}):\n",
        "{policy_text}\n",
        "\n",
        "CONTENT:\n",
        "{content}\n",
        "\n",
        "OUTPUT FORMAT:\n",
        "Return only JSON wrapped in triple backticks.\n",
        "\"\"\"\n",
        "\n",
        "        completion = client.chat.completions.create(\n",
        "            model=\"openai/gpt-oss-safeguard-20b\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0,\n",
        "            max_tokens=200,\n",
        "        )\n",
        "\n",
        "        raw = completion.choices[0].message.content.strip()\n",
        "\n",
        "        # Extract JSON between triple backticks\n",
        "        match = re.search(r\"```json(.*?)```\", raw, re.DOTALL)\n",
        "        if match:\n",
        "            json_str = match.group(1).strip()\n",
        "            try:\n",
        "                parsed = json.loads(json_str)\n",
        "            except json.JSONDecodeError:\n",
        "                parsed = {\"error\": \"Invalid JSON\", \"raw_output\": raw}\n",
        "        else:\n",
        "            parsed = {\"error\": \"No JSON found\", \"raw_output\": raw}\n",
        "\n",
        "        results[name] = parsed\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "vp6b3jJARfSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "policies = {\n",
        "    \"hate_speech\": \"Do not allow hate speech. Hate speech is defined as content that attacks or demeans a person or group based on race, religion, gender, or sexual orientation.\",\n",
        "    \"harassment\": \"Do not allow harassment. Harassment includes personal insults, bullying, or demeaning language directed at an individual.\"\n",
        "}\n",
        "\n",
        "content = \"You are such an idiot, nobody wants you here.\"\n",
        "\n",
        "results = classify_content(policies, content)\n",
        "\n",
        "for policy, outcome in results.items():\n",
        "    print(f\"\\nPolicy: {policy}\")\n",
        "    print(outcome)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eBnJBHdSEls",
        "outputId": "7f8e4112-533f-43d5-e893-372b09d69b7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Policy: hate_speech\n",
            "{'violation': False, 'category': 'not_applicable', 'rationale': 'The statement is a general insult and does not target a protected group based on race, religion, gender, or sexual orientation.', 'confidence': 0.99}\n",
            "\n",
            "Policy: harassment\n",
            "{'violation': True, 'category': 'harassment', 'rationale': 'The statement contains a personal insult and demeaning language directed at an individual.', 'confidence': 0.99}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8YsLR-NeSIMc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}